{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training LightGBM on the fraud dataset.\n",
    "- SMOTE for Upsampling\n",
    "- F1 score for metric\n",
    "- using early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import f1_score\n",
    "import warnings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = pd.read_csv('./data/x_train.csv').values\n",
    "y_train = pd.read_csv('./data/y_train.csv').values[:,0]\n",
    "x_test = pd.read_csv('./data/x_test.csv').values\n",
    "y_test = pd.read_csv('./data/y_test.csv').values[:,0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgb_f1_score(y_hat, data):\n",
    "    y_true = data.get_label()\n",
    "    y_hat = np.round(y_hat) # scikits f1 doesn't like probabilities\n",
    "    return 'f1', f1_score(y_true, y_hat), True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def objective(params):\n",
    "    print(params)\n",
    "    \n",
    "    num_leaves = int(params['num_leaves'])\n",
    "    min_data_in_leaf = int(params['min_data_in_leaf'])\n",
    "    max_bin = int(params['max_bin'])\n",
    "    bagging_fraction = params['bagging_fraction']\n",
    "    bagging_freq = int(params['bagging_freq'])\n",
    "    feature_fraction = params['feature_fraction']\n",
    "    lambda_l2 = params['lambda_l2'],\n",
    "    min_gain_to_split = params['min_gain_to_split']\n",
    "    scale_pos_weight = params['scale_pos_weight']\n",
    "    num_fraud = params['num_fraud']\n",
    "\n",
    "    param = {'num_leaves':num_leaves, \n",
    "             'min_data_in_leaf':min_data_in_leaf, \n",
    "             'max_bin':max_bin,\n",
    "             'learning_rate':0.1,\n",
    "             'num_trees':1000, \n",
    "             'objective':'binary',\n",
    "             'bagging_fraction':bagging_fraction,\n",
    "             'bagging_freq':bagging_freq,\n",
    "             'feature_fraction':feature_fraction,\n",
    "             #'verbose':-1,\n",
    "             'lambda_l2':lambda_l2,\n",
    "             'min_gain_to_split':min_gain_to_split,\n",
    "             'scale_pos_weight' : scale_pos_weight,\n",
    "            }\n",
    "\n",
    "    x_train_resampled, y_train_resampled = SMOTE(random_state = 42, \n",
    "                                                 sampling_strategy=num_fraud/227451\n",
    "                                                ).fit_resample(x_train, y_train)\n",
    " \n",
    "    train_data = lgb.Dataset(x_train_resampled, label=y_train_resampled)\n",
    "    test_data = lgb.Dataset(x_test, label=y_test)    \n",
    "\n",
    "    bst = lgb.train(param, \n",
    "                    train_data, \n",
    "                    valid_sets=[test_data], \n",
    "                    early_stopping_rounds=15, \n",
    "                    #verbose_eval=False,\n",
    "                    feval=lgb_f1_score, \n",
    "                   )\n",
    "\n",
    "    return bst\n",
    "    \n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bagging_fraction': 0.9997070861877592, 'bagging_freq': 20.0, 'feature_fraction': 0.6950759609275808, 'lambda_l2': 5.3205080171148165, 'max_bin': 2470.0, 'min_data_in_leaf': 289.0, 'min_gain_to_split': 0.6120818152340506, 'num_fraud': 460.0, 'num_leaves': 700.0, 'scale_pos_weight': 8.828004877536069}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/phmay/miniconda3/envs/py36/lib/python3.6/site-packages/lightgbm/engine.py:116: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's binary_logloss: 0.0232832\tvalid_0's f1: 0.681034\n",
      "Training until validation scores don't improve for 15 rounds.\n",
      "[2]\tvalid_0's binary_logloss: 0.0199374\tvalid_0's f1: 0.681034\n",
      "[3]\tvalid_0's binary_logloss: 0.0168572\tvalid_0's f1: 0.681034\n",
      "[4]\tvalid_0's binary_logloss: 0.0135264\tvalid_0's f1: 0.681034\n",
      "[5]\tvalid_0's binary_logloss: 0.0102002\tvalid_0's f1: 0.681034\n",
      "[6]\tvalid_0's binary_logloss: 0.00962852\tvalid_0's f1: 0.681034\n",
      "[7]\tvalid_0's binary_logloss: 0.00764848\tvalid_0's f1: 0.681034\n",
      "[8]\tvalid_0's binary_logloss: 0.00661451\tvalid_0's f1: 0.692308\n",
      "[9]\tvalid_0's binary_logloss: 0.00610566\tvalid_0's f1: 0.692308\n",
      "[10]\tvalid_0's binary_logloss: 0.00573049\tvalid_0's f1: 0.697872\n",
      "[11]\tvalid_0's binary_logloss: 0.00548064\tvalid_0's f1: 0.694915\n",
      "[12]\tvalid_0's binary_logloss: 0.00523716\tvalid_0's f1: 0.694915\n",
      "[13]\tvalid_0's binary_logloss: 0.00505158\tvalid_0's f1: 0.713043\n",
      "[14]\tvalid_0's binary_logloss: 0.00492209\tvalid_0's f1: 0.719298\n",
      "[15]\tvalid_0's binary_logloss: 0.00473386\tvalid_0's f1: 0.721739\n",
      "[16]\tvalid_0's binary_logloss: 0.00460596\tvalid_0's f1: 0.75\n",
      "[17]\tvalid_0's binary_logloss: 0.00450061\tvalid_0's f1: 0.756757\n",
      "[18]\tvalid_0's binary_logloss: 0.00441491\tvalid_0's f1: 0.760181\n",
      "[19]\tvalid_0's binary_logloss: 0.00429469\tvalid_0's f1: 0.770642\n",
      "[20]\tvalid_0's binary_logloss: 0.00420293\tvalid_0's f1: 0.767123\n",
      "[21]\tvalid_0's binary_logloss: 0.00412597\tvalid_0's f1: 0.770642\n",
      "[22]\tvalid_0's binary_logloss: 0.00407101\tvalid_0's f1: 0.781395\n",
      "[23]\tvalid_0's binary_logloss: 0.00395196\tvalid_0's f1: 0.792453\n",
      "[24]\tvalid_0's binary_logloss: 0.00389377\tvalid_0's f1: 0.8\n",
      "[25]\tvalid_0's binary_logloss: 0.00384301\tvalid_0's f1: 0.8\n",
      "[26]\tvalid_0's binary_logloss: 0.00376942\tvalid_0's f1: 0.803828\n",
      "[27]\tvalid_0's binary_logloss: 0.00372855\tvalid_0's f1: 0.803828\n",
      "[28]\tvalid_0's binary_logloss: 0.003684\tvalid_0's f1: 0.8\n",
      "[29]\tvalid_0's binary_logloss: 0.00364803\tvalid_0's f1: 0.803828\n",
      "[30]\tvalid_0's binary_logloss: 0.00358324\tvalid_0's f1: 0.807692\n",
      "[31]\tvalid_0's binary_logloss: 0.00352577\tvalid_0's f1: 0.807692\n",
      "[32]\tvalid_0's binary_logloss: 0.0034436\tvalid_0's f1: 0.807692\n",
      "[33]\tvalid_0's binary_logloss: 0.00339021\tvalid_0's f1: 0.811594\n",
      "[34]\tvalid_0's binary_logloss: 0.00331359\tvalid_0's f1: 0.811594\n",
      "[35]\tvalid_0's binary_logloss: 0.00322457\tvalid_0's f1: 0.815534\n",
      "[36]\tvalid_0's binary_logloss: 0.00317583\tvalid_0's f1: 0.815534\n",
      "[37]\tvalid_0's binary_logloss: 0.00313138\tvalid_0's f1: 0.825243\n",
      "[38]\tvalid_0's binary_logloss: 0.00307243\tvalid_0's f1: 0.825243\n",
      "[39]\tvalid_0's binary_logloss: 0.00302003\tvalid_0's f1: 0.825243\n",
      "[40]\tvalid_0's binary_logloss: 0.00296864\tvalid_0's f1: 0.833333\n",
      "[41]\tvalid_0's binary_logloss: 0.0029335\tvalid_0's f1: 0.837438\n",
      "[42]\tvalid_0's binary_logloss: 0.00289917\tvalid_0's f1: 0.837438\n",
      "[43]\tvalid_0's binary_logloss: 0.00284851\tvalid_0's f1: 0.837438\n",
      "[44]\tvalid_0's binary_logloss: 0.00282646\tvalid_0's f1: 0.841584\n",
      "[45]\tvalid_0's binary_logloss: 0.0028011\tvalid_0's f1: 0.861538\n",
      "[46]\tvalid_0's binary_logloss: 0.00277008\tvalid_0's f1: 0.861538\n",
      "[47]\tvalid_0's binary_logloss: 0.00273652\tvalid_0's f1: 0.865979\n",
      "[48]\tvalid_0's binary_logloss: 0.00272271\tvalid_0's f1: 0.870466\n",
      "[49]\tvalid_0's binary_logloss: 0.00270517\tvalid_0's f1: 0.875\n",
      "[50]\tvalid_0's binary_logloss: 0.00268692\tvalid_0's f1: 0.875\n",
      "[51]\tvalid_0's binary_logloss: 0.00267\tvalid_0's f1: 0.875\n",
      "[52]\tvalid_0's binary_logloss: 0.00266074\tvalid_0's f1: 0.884211\n",
      "[53]\tvalid_0's binary_logloss: 0.00265417\tvalid_0's f1: 0.875\n",
      "[54]\tvalid_0's binary_logloss: 0.00264203\tvalid_0's f1: 0.884211\n",
      "[55]\tvalid_0's binary_logloss: 0.00263734\tvalid_0's f1: 0.884211\n",
      "[56]\tvalid_0's binary_logloss: 0.00262665\tvalid_0's f1: 0.888889\n",
      "[57]\tvalid_0's binary_logloss: 0.00261861\tvalid_0's f1: 0.893617\n",
      "[58]\tvalid_0's binary_logloss: 0.00261589\tvalid_0's f1: 0.888889\n",
      "[59]\tvalid_0's binary_logloss: 0.00260761\tvalid_0's f1: 0.893617\n",
      "[60]\tvalid_0's binary_logloss: 0.00260848\tvalid_0's f1: 0.893617\n",
      "[61]\tvalid_0's binary_logloss: 0.00260555\tvalid_0's f1: 0.893617\n",
      "[62]\tvalid_0's binary_logloss: 0.00260724\tvalid_0's f1: 0.893617\n",
      "[63]\tvalid_0's binary_logloss: 0.00259953\tvalid_0's f1: 0.893617\n",
      "[64]\tvalid_0's binary_logloss: 0.00259543\tvalid_0's f1: 0.893617\n",
      "[65]\tvalid_0's binary_logloss: 0.00259221\tvalid_0's f1: 0.888889\n",
      "[66]\tvalid_0's binary_logloss: 0.00258621\tvalid_0's f1: 0.888889\n",
      "[67]\tvalid_0's binary_logloss: 0.00258767\tvalid_0's f1: 0.888889\n",
      "[68]\tvalid_0's binary_logloss: 0.00258881\tvalid_0's f1: 0.888889\n",
      "[69]\tvalid_0's binary_logloss: 0.00258536\tvalid_0's f1: 0.888889\n",
      "[70]\tvalid_0's binary_logloss: 0.00258624\tvalid_0's f1: 0.888889\n",
      "[71]\tvalid_0's binary_logloss: 0.00258264\tvalid_0's f1: 0.888889\n",
      "[72]\tvalid_0's binary_logloss: 0.00258148\tvalid_0's f1: 0.893617\n",
      "Early stopping, best iteration is:\n",
      "[57]\tvalid_0's binary_logloss: 0.00261861\tvalid_0's f1: 0.893617\n"
     ]
    }
   ],
   "source": [
    "best = {'bagging_fraction': 0.9997070861877592, 'bagging_freq': 20.0, 'feature_fraction': 0.6950759609275808, \n",
    "        'lambda_l2': 5.3205080171148165, 'max_bin': 2470.0, 'min_data_in_leaf': 289.0, \n",
    "        'min_gain_to_split': 0.6120818152340506, 'num_fraud': 460.0, 'num_leaves': 700.0, 'scale_pos_weight': 8.828004877536069\n",
    "       }\n",
    "\n",
    "booster = objective(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions: [4.63248435e-05 9.81981277e-05 2.61699537e-03 ... 5.95966967e-05\n",
      " 9.23186404e-05 4.81079780e-04]\n",
      "predictions.shape: (56962,)\n"
     ]
    }
   ],
   "source": [
    "predictions = booster.predict(x_test)\n",
    "\n",
    "print('predictions:', predictions)\n",
    "\n",
    "print('predictions.shape:', predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score: 0.8936170212765957\n"
     ]
    }
   ],
   "source": [
    "y_hat = np.round(predictions) # scikits f1 doesn't like probabilities\n",
    "f1_score = f1_score(y_test, y_hat)\n",
    "\n",
    "print('f1_score:', f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
